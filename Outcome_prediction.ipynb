{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission statement #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to build a neural network predicting the outcome of a match, given the hero matchup (5 radiant heroes and 5 dire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import math\n",
    "import time\n",
    "from tensorflow import keras\n",
    "#from tqdm import tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the hero dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = requests.get(\"https://api.opendota.com/api/heroes\")\n",
    "hero_df = pd.DataFrame(json.loads(h.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine the required data #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get high-mmr matches, using OpenDota API which gives a random sample of 100 recent games. Work iteratively - per every call, sort out the 100 matches, get 100 older matches and repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickaxe(below_match_id = None):\n",
    "    \n",
    "    # Pick out relevant matches from a sample of 100\n",
    "    \n",
    "    if below_match_id == None:\n",
    "        string = 'https://api.opendota.com/api/publicMatches'\n",
    "    else:\n",
    "        string = 'https://api.opendota.com/api/publicMatches?less_than_match_id=' + str(below_match_id)\n",
    "    A = requests.get(string).json()\n",
    "    over4k = []\n",
    "    for i in range(len(A)):\n",
    "        try:\n",
    "            if A[i].get('avg_mmr', None) is not None:\n",
    "                if A[i]['game_mode'] == 22 and A[i]['avg_mmr'] > 4000:\n",
    "                    over4k.append(A[i])\n",
    "        except: return over4k, below_match_id\n",
    "    lowest_match_id = A[-1]['match_id']\n",
    "    return over4k, lowest_match_id\n",
    "\n",
    "def picked_heroes(hero_string):\n",
    "    \n",
    "    # Convert the string from pickaxe() to a length 116 array with 1s on picked heroes, 0 elsewhere.\n",
    "    \n",
    "    team_input = np.zeros(len(hero_df))\n",
    "    y = [int(i) for i in hero_string.split(',')]\n",
    "    for item in y:\n",
    "        idx = int(hero_df[hero_df['id'] == item].index[0])\n",
    "        team_input[idx] += 1\n",
    "    return team_input\n",
    "\n",
    "def process_the_pickaxe(game_list):\n",
    "    Xt = np.zeros(232)\n",
    "    yt = np.array(0)\n",
    "    for item in game_list:\n",
    "        X = np.hstack((picked_heroes(item['radiant_team']), picked_heroes(item['dire_team'])))\n",
    "        y = np.array(0)\n",
    "        y += item['radiant_win']*1\n",
    "        Xt = np.vstack((Xt,X))\n",
    "        yt = np.vstack((yt,y))\n",
    "    Xt = np.delete(Xt, 0, 0)\n",
    "    yt = np.delete(yt, 0, 0)\n",
    "    if Xt.shape == (231,):\n",
    "        Xt = None\n",
    "        yt = None\n",
    "    return Xt, yt\n",
    "\n",
    "def single_call(last_match_id = None):\n",
    "    \n",
    "    # Perform a call for 100 matches and process it.\n",
    "    \n",
    "    if last_match_id == None:\n",
    "        a,c = pickaxe()\n",
    "    else:\n",
    "        a,c = pickaxe(last_match_id)\n",
    "    X_4, y_4 = process_the_pickaxe(a)\n",
    "    return X_4, y_4, c\n",
    "\n",
    "def multiple_calls(call_number = 60, last_match_id = None):\n",
    "    Total_X_4 = np.zeros(232)\n",
    "    Total_y_4 = np.array(0)\n",
    "    for i in tqdm_notebook(range(call_number)):\n",
    "        if i % 60 == 0 and i > 0:\n",
    "            time.sleep(70)\n",
    "        X_4, y_4, last_match_id = single_call(last_match_id = last_match_id)\n",
    "        if X_4 is not None:\n",
    "            Total_X_4 = np.vstack((Total_X_4, X_4))\n",
    "            Total_y_4 = np.vstack((Total_y_4, y_4))\n",
    "    Total_X_4 = np.delete(Total_X_4, 0, 0)\n",
    "    Total_y_4 = np.delete(Total_y_4, 0, 0)\n",
    "    return Total_X_4, Total_y_4, last_match_id\n",
    "\n",
    "def final_processing(X,y, test_ratio = 0.1):\n",
    "    N = int(np.ceil(len(X)*test_ratio))\n",
    "    X_test = X[:N]\n",
    "    y_test = y[:N]\n",
    "    X_train = X[N:]\n",
    "    y_train = y[N:]\n",
    "    return X_train, y_train, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02da7e7b9152494eb6245a4a738a5ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gintas\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:41: DeprecationWarning: in the future the special handling of scalars will be removed from delete and raise an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and target sizes: (44899, 232) (44899, 1)\n"
     ]
    }
   ],
   "source": [
    "X4, y4, _ = multiple_calls(call_number = 6000)\n",
    "print('Data and target sizes:', X4.shape, y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = final_processing(X4,y4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save onto pickled files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'X4'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(X4,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'y4'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(y4,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4439774104"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the pickled files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('X4','rb')\n",
    "XX4 = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('y4','rb')\n",
    "yy4 = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = XX4\n",
    "y4 = yy4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handy tool to convert heroes to an numpy 232 array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_array(radiant,dire):\n",
    "    X = np.zeros(232)\n",
    "    for item in radiant:\n",
    "        idx = hero_df[hero_df['localized_name']==item].index[0]\n",
    "        X[idx] += 1\n",
    "    for item in dire:\n",
    "        idx = hero_df[hero_df['localized_name']==item].index[0] + 116\n",
    "        X[idx] +=1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attack_type</th>\n",
       "      <th>id</th>\n",
       "      <th>legs</th>\n",
       "      <th>localized_name</th>\n",
       "      <th>name</th>\n",
       "      <th>primary_attr</th>\n",
       "      <th>roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Melee</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Anti-Mage</td>\n",
       "      <td>npc_dota_hero_antimage</td>\n",
       "      <td>agi</td>\n",
       "      <td>[Carry, Escape, Nuker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melee</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Axe</td>\n",
       "      <td>npc_dota_hero_axe</td>\n",
       "      <td>str</td>\n",
       "      <td>[Initiator, Durable, Disabler, Jungler]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ranged</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Bane</td>\n",
       "      <td>npc_dota_hero_bane</td>\n",
       "      <td>int</td>\n",
       "      <td>[Support, Disabler, Nuker, Durable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melee</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Bloodseeker</td>\n",
       "      <td>npc_dota_hero_bloodseeker</td>\n",
       "      <td>agi</td>\n",
       "      <td>[Carry, Disabler, Jungler, Nuker, Initiator]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ranged</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Crystal Maiden</td>\n",
       "      <td>npc_dota_hero_crystal_maiden</td>\n",
       "      <td>int</td>\n",
       "      <td>[Support, Disabler, Nuker, Jungler]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  attack_type  id  legs  localized_name                          name  \\\n",
       "0       Melee   1     2       Anti-Mage        npc_dota_hero_antimage   \n",
       "1       Melee   2     2             Axe             npc_dota_hero_axe   \n",
       "2      Ranged   3     4            Bane            npc_dota_hero_bane   \n",
       "3       Melee   4     2     Bloodseeker     npc_dota_hero_bloodseeker   \n",
       "4      Ranged   5     2  Crystal Maiden  npc_dota_hero_crystal_maiden   \n",
       "\n",
       "  primary_attr                                         roles  \n",
       "0          agi                        [Carry, Escape, Nuker]  \n",
       "1          str       [Initiator, Durable, Disabler, Jungler]  \n",
       "2          int           [Support, Disabler, Nuker, Durable]  \n",
       "3          agi  [Carry, Disabler, Jungler, Nuker, Initiator]  \n",
       "4          int           [Support, Disabler, Nuker, Jungler]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hero_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attack_type</th>\n",
       "      <th>id</th>\n",
       "      <th>legs</th>\n",
       "      <th>localized_name</th>\n",
       "      <th>name</th>\n",
       "      <th>primary_attr</th>\n",
       "      <th>roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Melee</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>Lycan</td>\n",
       "      <td>npc_dota_hero_lycan</td>\n",
       "      <td>str</td>\n",
       "      <td>[Carry, Pusher, Jungler, Durable, Escape]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attack_type  id  legs localized_name                 name primary_attr  \\\n",
       "75       Melee  77     2          Lycan  npc_dota_hero_lycan          str   \n",
       "\n",
       "                                        roles  \n",
       "75  [Carry, Pusher, Jungler, Durable, Escape]  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hero_df[hero_df['localized_name']=='Lycan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_138 (Dense)            (None, 64)                14912     \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 17,265\n",
      "Trainable params: 17,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36368 samples, validate on 4041 samples\n",
      "Epoch 1/5\n",
      "36368/36368 [==============================] - 11s 305us/step - loss: 0.6864 - acc: 0.5512 - val_loss: 0.6746 - val_acc: 0.5783\n",
      "Epoch 2/5\n",
      "36368/36368 [==============================] - 8s 227us/step - loss: 0.6773 - acc: 0.5752 - val_loss: 0.6748 - val_acc: 0.5734\n",
      "Epoch 3/5\n",
      "36368/36368 [==============================] - 8s 215us/step - loss: 0.6751 - acc: 0.5792 - val_loss: 0.6750 - val_acc: 0.5791\n",
      "Epoch 4/5\n",
      "18660/36368 [==============>...............] - ETA: 3s - loss: 0.6736 - acc: 0.5801"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim = 232, activation = 'tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation = 'tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation = 'tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X_train,y_train, validation_split = 0.1 ,batch_size = 10, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on the test set:', model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radiant win probability is 0.5870339\n"
     ]
    }
   ],
   "source": [
    "radiant =[]\n",
    "dire = ['Invoker'] \n",
    "X_toy = string_to_array(radiant,dire)\n",
    "X_toy = X_toy.reshape((1,-1))\n",
    "print('Radiant win probability is', model.predict(X_toy)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an easy-to-input hero list: (later..) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hero_to_id(string):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playground:####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gintas\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Gintas\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.5287305122494432\n",
      "Training score: 0.9873543022593977\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "print('Testing score:', rf.score(X_test,y_test))\n",
    "print('Training score:', rf.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gintas\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training test: 0.592838229107377\n",
      "Score on test test: 0.5761692650334076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train,y_train)\n",
    "print('Score on training test:', gbm.score(X_train,y_train))\n",
    "print('Score on test test:', gbm.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gintas\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Gintas\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score: 0.5953229398663697\n",
      "Training score: 0.5880373184191641\n"
     ]
    }
   ],
   "source": [
    "Cs = np.logspace(-2,5,10)\n",
    "lr = LogisticRegressionCV(Cs=Cs)\n",
    "lr.fit(X_train,y_train)\n",
    "print('Testing score:', lr.score(X_test,y_test))\n",
    "print('Training score:', lr.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
